{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb24f001",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "trainingBin <- read.csv(\"insurance_t_bin.csv\") \n",
    "training <- read.csv(\"insurance_t.csv\") \n",
    "\n",
    "validationBin <- read.csv(\"insurance_v_bin.csv\") \n",
    "validation <- read.csv(\"insurance_v.csv\") \n",
    "\n",
    "# Fixing Separations and NAs\n",
    "trainingBin <- trainingBin %>% mutate(across(everything(), ~ as.character(.x))) %>% \n",
    "  mutate(across(everything(), ~ replace_na(.x,\"M\"))) %>% \n",
    "  mutate(across(everything(), ~ as.factor(.x)))\n",
    "\n",
    "validationBin <- validationBin %>% mutate(across(everything(), ~ as.character(.x))) %>% \n",
    "  mutate(across(everything(), ~ replace_na(.x,\"M\"))) %>% \n",
    "  mutate(across(everything(), ~ as.factor(.x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9276ac7",
   "metadata": {},
   "source": [
    "# Old Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af502d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModel <- glm(INS ~ NSF + MTG + INV + ILSBAL_BIN + IRA + DDA + TELLER_BIN + CC + ATMAMT_BIN + CHECKS_BIN + MMBAL_BIN + CDBAL_BIN + DDABAL_BIN + SAVBAL_BIN + DDA:IRA,family = binomial(link = \"logit\"),data = trainingBin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef061889",
   "metadata": {},
   "source": [
    "# Decision Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ee5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a large tree to prune later. The values I selected are what I came to after playing around with various models.\n",
    "\n",
    "# Only LR variables\n",
    "lrTree <- rpart(INS ~ NSF + MTG + INV + ILSBAL + IRA + DDA + TELLER + CC + ATMAMT + CHECKS + MMBAL + CDBAL + DDABAL + SAVBAL, data=training, method='class',parms = list(split=\"gini\"),\n",
    "                    control = rpart.control(minsplit = 30, cp = .001, maxdepth = 6))\n",
    "# All variables\n",
    "bigTree <- rpart(INS ~ ., data=training, method='class',parms = list(split=\"gini\"),\n",
    "                       control = rpart.control(minsplit = 30, cp = .001, maxdepth = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9788ac2",
   "metadata": {},
   "source": [
    "## Pruning\n",
    "\n",
    "### Subset Variable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "printcp(lrTree)\n",
    "\n",
    "## \n",
    "## Classification tree:\n",
    "## rpart(formula = INS ~ NSF + MTG + INV + ILSBAL + IRA + DDA + \n",
    "##     TELLER + CC + ATMAMT + CHECKS + MMBAL + CDBAL + DDABAL + \n",
    "##     SAVBAL, data = training, method = \"class\", parms = list(split = \"gini\"), \n",
    "##     control = rpart.control(minsplit = 30, cp = 0.001, maxdepth = 6))\n",
    "## \n",
    "## Variables actually used in tree construction:\n",
    "##  [1] ATMAMT CDBAL  CHECKS DDA    DDABAL INV    IRA    MMBAL  MTG    SAVBAL TELLER\n",
    "## \n",
    "## Root node error: 2918/8495 = 0.3435\n",
    "## \n",
    "## n= 8495 \n",
    "## \n",
    "##           CP nsplit rel error  xerror     xstd\n",
    "## 1  0.1329678      0   1.00000 1.00000 0.014999\n",
    "## 2  0.0277587      1   0.86703 0.87320 0.014474\n",
    "## 3  0.0099383      2   0.83927 0.83790 0.014300\n",
    "## 4  0.0056546      5   0.80946 0.82762 0.014248\n",
    "## 5  0.0054832     10   0.78033 0.82351 0.014226\n",
    "## 6  0.0049692     11   0.77485 0.81905 0.014203\n",
    "## 7  0.0035984     13   0.76491 0.81254 0.014168\n",
    "## 8  0.0032557     15   0.75771 0.80672 0.014137\n",
    "## 9  0.0027416     17   0.75120 0.80158 0.014109\n",
    "## 10 0.0023989     18   0.74846 0.80363 0.014120\n",
    "## 11 0.0020562     19   0.74606 0.80329 0.014118\n",
    "## 12 0.0017135     23   0.73783 0.79952 0.014098\n",
    "## 13 0.0010281     24   0.73612 0.79644 0.014081\n",
    "## 14 0.0010000     28   0.73201 0.79507 0.014073"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb0ccf",
   "metadata": {},
   "source": [
    "Only want to include first 6 layers based on oneSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrTree <- prune(lrTree,cp=0.0049692)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb732e2",
   "metadata": {},
   "source": [
    "### Full Variable Model Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "printcp(bigTree)\n",
    "\n",
    "## \n",
    "## Classification tree:\n",
    "## rpart(formula = INS ~ ., data = training, method = \"class\", parms = list(split = \"gini\"), \n",
    "##     control = rpart.control(minsplit = 30, cp = 0.001, maxdepth = 6))\n",
    "## \n",
    "## Variables actually used in tree construction:\n",
    "##  [1] ACCTAGE ATMAMT  BRANCH  CDBAL   CHECKS  CRSCORE DDA     DDABAL  DEP     MM      SAVBAL \n",
    "## \n",
    "## Root node error: 2918/8495 = 0.3435\n",
    "## \n",
    "## n= 8495 \n",
    "## \n",
    "##           CP nsplit rel error  xerror     xstd\n",
    "## 1  0.1329678      0   1.00000 1.00000 0.014999\n",
    "## 2  0.0277587      1   0.86703 0.87320 0.014474\n",
    "## 3  0.0119945      2   0.83927 0.84030 0.014313\n",
    "## 4  0.0111378      3   0.82728 0.82419 0.014230\n",
    "## 5  0.0090816      5   0.80500 0.81905 0.014203\n",
    "## 6  0.0065798      7   0.78684 0.81357 0.014174\n",
    "## 7  0.0065113     12   0.75394 0.80295 0.014117\n",
    "## 8  0.0034270     13   0.74743 0.79609 0.014079\n",
    "## 9  0.0030843     14   0.74400 0.79232 0.014058\n",
    "## 10 0.0020562     15   0.74092 0.79130 0.014052\n",
    "## 11 0.0017135     17   0.73681 0.80055 0.014103\n",
    "## 12 0.0015422     19   0.73338 0.79986 0.014100\n",
    "## 13 0.0013708     22   0.72824 0.80329 0.014118\n",
    "## 14 0.0010281     24   0.72550 0.80363 0.014120\n",
    "## 15 0.0010000     25   0.72447 0.80295 0.014117"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2e170",
   "metadata": {},
   "source": [
    "Only want first 10 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a42eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigTree <- prune(bigTree,cp=0.0020562)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0876bc9",
   "metadata": {},
   "source": [
    "# Visualizing\n",
    "\n",
    "## Subset Variable Model\n",
    "\n",
    "![](HW2Final_files/figure-markdown_strict/unnamed-chunk-9-1.png)\n",
    "\n",
    "## Full Variable Model\n",
    "\n",
    "![](HW2Final_files/figure-markdown_strict/unnamed-chunk-10-1.png)\n",
    "\n",
    "# Accuracy scores\n",
    "\n",
    "## Predictions and Fitted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "probLRTree <- predict(lrTree,validation,type = \"prob\")\n",
    "probBigTree <- predict(bigTree,validation,type = \"prob\")\n",
    "\n",
    "predLRTree <- predict(lrTree,validation,type = \"class\")\n",
    "predBigTree <- predict(bigTree,validation,type = \"class\")\n",
    "\n",
    "fittedLRTree <- predict(lrTree,training,type = \"prob\")\n",
    "fittedBigTree <- predict(bigTree,training,type = \"prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e3a49",
   "metadata": {},
   "source": [
    "## Subset Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrAccuracy <- (length((which(predLRTree == validation$INS))) / nrow(validation))\n",
    "\n",
    "lrAccuracy\n",
    "\n",
    "## [1] 0.7123352"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d01a8a",
   "metadata": {},
   "source": [
    "## Full Variable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e811edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigAccuracy <- (length((which(predBigTree == validation$INS))) / nrow(validation))\n",
    "\n",
    "bigAccuracy\n",
    "\n",
    "## [1] 0.7306968"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860aa112",
   "metadata": {},
   "source": [
    "## Logistic Regression Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa506466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from logistic regression ROC curve\n",
    "cutoff <-  0.2970672\n",
    "pred <- predict(finalModel,validationBin,type = \"response\")\n",
    "pred <- data.frame(pred = pred) %>% mutate(pred = if_else(pred > cutoff,1,0))\n",
    "pred <- pred$pred\n",
    "\n",
    "# Create accuracy vector\n",
    "accDF <- data.frame(pred = pred, observed = validation$INS) %>% mutate(accuracy = if_else(pred == observed,1,0))\n",
    "\n",
    "accuracy <- round(mean(accDF$accuracy),4)\n",
    "# Accuracy \n",
    "accuracy\n",
    "\n",
    "## [1] 0.702"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf16a05",
   "metadata": {},
   "source": [
    "Seeing as how the full variable tree outperforms both the logistic\n",
    "regression, and the model built on a smaller set of variables. The\n",
    "larger tree does not add too much complication"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
